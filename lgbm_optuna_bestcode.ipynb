{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfebd8-f440-42a1-9cf7-27e4160c6cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm optuna\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs, Descriptors\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "\n",
    "CFG = {\n",
    "    'SEED': 42,\n",
    "    'NBITS': 2048,\n",
    "    'N_SPLITS': 5,\n",
    "    'LEARNING_RATE': 0.01,\n",
    "    'EARLY_STOPPING_ROUNDS': 100,\n",
    "    'N_ESTIMATORS': 5000\n",
    "}\n",
    "\n",
    "OPTUNA_TRIALS = 100\n",
    "N_SPLITS = CFG['N_SPLITS']\n",
    "ESR = CFG['EARLY_STOPPING_ROUNDS']\n",
    "\n",
    "def get_lgbm_params(seed):\n",
    "    return dict(\n",
    "        objective='regression',\n",
    "        learning_rate=CFG['LEARNING_RATE'],\n",
    "        num_leaves=64,\n",
    "        feature_fraction=0.9,\n",
    "        bagging_fraction=0.8,\n",
    "        bagging_freq=1,\n",
    "        min_child_samples=20,\n",
    "        random_state=seed,\n",
    "        verbose=-1\n",
    "    )\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(CFG['SEED'])\n",
    "\n",
    "# ========== Utis ==========\n",
    "def IC50_to_pIC50(ic50_nM):\n",
    "    ic50_nM = np.clip(ic50_nM, 1e-12, None)\n",
    "    return 9 - np.log10(ic50_nM)\n",
    "def pIC50_to_IC50(pIC50): return 10**(9 - pIC50)\n",
    "\n",
    "def bv_to_np(bitvect, nbits):\n",
    "    arr = np.zeros((nbits,), dtype=np.uint8)\n",
    "    DataStructs.ConvertToNumpyArray(bitvect, arr)\n",
    "    return arr\n",
    "\n",
    "# ========== Data ==========\n",
    "def preprocess_data():\n",
    "    chembl = pd.read_csv(\"./ChEMBL_ASK1(IC50).csv\", sep=';')\n",
    "    pubchem = pd.read_csv(\"./Pubchem_ASK1.csv\")\n",
    "\n",
    "    tsv_add = pd.read_csv(\"./1_11.tsv\", sep='\\t')\n",
    "    tsv_add = tsv_add[['Ligand SMILES', 'IC50 (nM)']].rename(columns={\n",
    "        'Ligand SMILES': 'smiles',\n",
    "        'IC50 (nM)': 'ic50'\n",
    "    })\n",
    "\n",
    "    chembl.columns = chembl.columns.str.strip().str.replace('\"','')\n",
    "    chembl = chembl[['Smiles', 'Standard Value']].rename(columns={'Smiles': 'smiles', 'Standard Value': 'ic50'})\n",
    "    if 'Standard Type' in chembl.columns and chembl['Standard Type'].nunique() > 1:\n",
    "        chembl = chembl[chembl['Standard Type'] == 'IC50']\n",
    "\n",
    "    pubchem = pubchem[['SMILES', 'Activity_Value']].rename(columns={'SMILES': 'smiles', 'Activity_Value': 'ic50'})\n",
    "\n",
    "    chembl['ic50'] = pd.to_numeric(chembl['ic50'], errors='coerce')\n",
    "    pubchem['ic50'] = pd.to_numeric(pubchem['ic50'], errors='coerce')\n",
    "    tsv_add['ic50'] = pd.to_numeric(tsv_add['ic50'], errors='coerce')\n",
    "\n",
    "    chembl['source'] = 'chembl'\n",
    "    pubchem['source'] = 'pubchem'\n",
    "    tsv_add['source'] = 'extra'\n",
    "\n",
    "    df = pd.concat([chembl, pubchem, tsv_add], ignore_index=True)\n",
    "    df = df.dropna(subset=['smiles', 'ic50'])\n",
    "    df = df[df['ic50'] > 0]\n",
    "    df = df.drop_duplicates(subset='smiles').reset_index(drop=True)\n",
    "\n",
    "\n",
    "    df['pIC50'] = IC50_to_pIC50(df['ic50'])\n",
    "\n",
    "    print(f\"전처리 완료: 총 {len(df)}개 샘플\")\n",
    "    print(\"소스별 샘플 수:\\n\", df['source'].value_counts())\n",
    "    return df\n",
    "    \n",
    "\n",
    "# ========= 2) Fingerprint 생성기 =========\n",
    "def fp_morgan(smiles, radius=2, nBits=CFG['NBITS']):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    bv = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=nBits)\n",
    "    return bv_to_np(bv, nBits)\n",
    "\n",
    "def smiles_to_morgan_fp(smiles, radius=2, nBits=CFG['NBITS']):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)\n",
    "    arr = np.zeros((nBits,), dtype=np.uint8)     # 길이 반드시 nBits\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return arr\n",
    "\n",
    "def calculate_rdkit_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.full((len(Descriptors._descList),), np.nan, dtype=float)\n",
    "    try:\n",
    "        vals = [fn(mol) for _, fn in Descriptors._descList]\n",
    "    except Exception:\n",
    "        return np.full((len(Descriptors._descList),), np.nan, dtype=float)\n",
    "    return np.array(vals, dtype=float)\n",
    "\n",
    "def get_score(y_true_ic50, y_pred_ic50, y_true_pic50, y_pred_pic50):\n",
    "    rmse = mean_squared_error(y_true_ic50, y_pred_ic50)\n",
    "    nrmse = rmse / (np.max(y_true_ic50) - np.min(y_true_ic50))\n",
    "    A = 1 - min(nrmse, 1)\n",
    "    B = r2_score(y_true_pic50, y_pred_pic50)\n",
    "    score = 0.4 * A + 0.6 * B\n",
    "    return score\n",
    "\n",
    "\n",
    "# ========== Morgan + RDkit 결합 피처 생성 ==========\n",
    "def build_X_morgan_plus_rdkit(df, radius=2, nBits=CFG['NBITS']):\n",
    "    # Morgan FP\n",
    "    morgan_list, keep_idx = [], []\n",
    "    for i, smi in enumerate(df['smiles']):\n",
    "        x = fp_morgan(smi, radius, nBits=nBits)\n",
    "        if x is not None:\n",
    "            morgan_list.append(x); keep_idx.append(i)\n",
    "    sub = df.iloc[keep_idx].copy()\n",
    "    X_morgan = np.stack(morgan_list)\n",
    "\n",
    "    rd_list = [calculate_rdkit_descriptors(smi) for smi in sub['smiles']]\n",
    "    X_rd = np.vstack(rd_list)\n",
    "\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    scaler = StandardScaler()\n",
    "    X_rd_imputed = imputer.fit_transform(X_rd)\n",
    "    X_rd_scaled  = scaler.fit_transform(X_rd_imputed)\n",
    "\n",
    "    # 결합\n",
    "    X = np.hstack([X_morgan.astype(np.float32), X_rd_scaled.astype(np.float32)])\n",
    "\n",
    "    # 타깃\n",
    "    y_pic50 = sub['pIC50'].values.astype(float)\n",
    "    y_ic50 = sub['ic50'].values.astype(float)\n",
    "\n",
    "    desc_mean = np.nanmean(X_rd, axis=0)\n",
    "    \n",
    "    return X, y_pic50, y_ic50, sub, imputer, scaler, desc_mean\n",
    "\n",
    "def comp_metric_sklearn(y_true, y_pred):\n",
    "    y_true_ic50 = pIC50_to_IC50(y_true)\n",
    "    y_pred_ic50 = pIC50_to_IC50(y_pred)\n",
    "\n",
    "    score = get_score(y_true_ic50, y_pred_ic50, y_true, y_pred)\n",
    "    return 'comp_score', score, True  # True: 높을수록 좋음\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # 탐색할 하이퍼파라미터 공간\n",
    "    params = dict(\n",
    "        objective='regression',\n",
    "        learning_rate=trial.suggest_float('learning_rate', 1e-3, 3e-1, log=True),\n",
    "        num_leaves=trial.suggest_int('num_leaves', 31, 255),\n",
    "        feature_fraction=trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        bagging_fraction=trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
    "        bagging_freq=trial.suggest_int('bagging_freq', 0, 5),\n",
    "        min_child_samples=trial.suggest_int('min_child_samples', 5, 60),\n",
    "        reg_alpha=trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        reg_lambda=trial.suggest_float('reg_lambda', 0.0, 3.0),\n",
    "        random_state=CFG['SEED'],\n",
    "        verbose=-1,\n",
    "        n_estimators=CFG['N_ESTIMATORS'],\n",
    "    )\n",
    "\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=CFG['SEED'])\n",
    "    oof_pred_pic50 = np.zeros_like(y_pic50c, dtype=float)\n",
    "\n",
    "    fold_scores = []\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(Xc_df), 1):\n",
    "        X_tr, X_va = Xc_df.iloc[tr_idx].values, Xc_df.iloc[va_idx].values\n",
    "        y_tr, y_va = y_pic50c[tr_idx], y_pic50c[va_idx]\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            eval_metric=comp_metric_sklearn,\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=ESR, verbose=False)]\n",
    "        )\n",
    "        \n",
    "        y_pred_va = model.predict(X_va, num_iteration=model.best_iteration_)\n",
    "        oof_pred_pic50[va_idx] = y_pred_va\n",
    "\n",
    "        y_va_ic50 = pIC50_to_IC50(y_va)\n",
    "        y_pred_va_ic50 = pIC50_to_IC50(y_pred_va)\n",
    "        score, A, B, rmse = comp_score(y_va_ic50, y_pred_va_ic50, y_va, y_pred_va)\n",
    "\n",
    "        print(f\"[Trial {trial.number}] Fold {fold} → Score={score:.4f}, A={A:.4f}, B={B:.4f}, RMSE(IC50)={rmse:.4f}\")\n",
    "\n",
    "    # OOF 종합 점수\n",
    "    y_oof_ic50 = pIC50_to_IC50(oof_pred_pic50)\n",
    "    score, A, B, rmse = comp_score(y_ic50c, y_oof_ic50, y_pic50c, oof_pred_pic50)\n",
    "\n",
    "    print(f\"[Trial {trial.number}] OOF 결과 → Score={score:.4f}, A={A:.4f}, B={B:.4f}, RMSE(IC50)={rmse:.4f}\")\n",
    "\n",
    "    trial.set_user_attr(\"A\", A)\n",
    "    trial.set_user_attr(\"B\", B)\n",
    "    trial.set_user_attr(\"RMSE(IC50)\", rmse)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def train_oof_ensemble(best_params: dict):\n",
    "    \"\"\"Best params로 KFold 앙상블 학습해 object(리스트) 반환\"\"\"\n",
    "    models = []\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=CFG['SEED'])\n",
    "    for tr_idx, va_idx in kf.split(Xc_df):\n",
    "        # DataFrame 그대로 사용 (values 제거)\n",
    "        X_tr, X_va = Xc_df.iloc[tr_idx], Xc_df.iloc[va_idx]\n",
    "        y_tr, y_va = y_pic50c[tr_idx], y_pic50c[va_idx]\n",
    "    \n",
    "        model = lgb.LGBMRegressor(**best_params, n_estimators=CFG['N_ESTIMATORS'])\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            eval_metric=comp_metric_sklearn,\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=ESR, verbose=False)]\n",
    "        )\n",
    "        models.append(model)\n",
    "\n",
    "    return models\n",
    "\n",
    "def predict_with_ensemble(models, X_test_df: pd.DataFrame) -> np.ndarray:\n",
    "    preds = np.zeros(len(X_test_df), dtype=float)\n",
    "    for m in models:\n",
    "        preds += m.predict(X_test_df, num_iteration=m.best_iteration_) / len(models)\n",
    "    return preds\n",
    "\n",
    "def comp_score(y_true_ic50, y_pred_ic50, y_true_pic50, y_pred_pic50):\n",
    "    rmse = mean_squared_error(y_true_ic50, y_pred_ic50)\n",
    "    nrmse = rmse / (np.max(y_true_ic50) - np.min(y_true_ic50))\n",
    "    A = 1 - min(nrmse, 1)\n",
    "    B = r2_score(y_true_pic50, y_pred_pic50)\n",
    "    score = 0.4 * A + 0.6 * B\n",
    "    return score, A, B, rmse\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = preprocess_data()\n",
    "    Xc, y_pic50c, y_ic50c, subc, imputer, scaler, desc_mean = build_X_morgan_plus_rdkit(df, radius=2, nBits=CFG['NBITS'])\n",
    "\n",
    "    morgan_feature_names = [f\"morgan_{i}\" for i in range(CFG['NBITS'])]\n",
    "    rd_dim = len(Descriptors._descList)\n",
    "    rdkit_feature_names = [f\"rdkit_{i}\" for i in range(rd_dim)]\n",
    "    feature_names = morgan_feature_names + rdkit_feature_names\n",
    "    Xc_df = pd.DataFrame(Xc, columns=feature_names)\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=CFG['SEED'])\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=OPTUNA_TRIALS, show_progress_bar=False)\n",
    "\n",
    "    best = study.best_trial\n",
    "    score = best.value\n",
    "    print(f\"Best trial: {best.number}. Best value: {best.value:.6f}\")\n",
    "    print(\"Best params:\", best.params)\n",
    "    print(f\"[lgbm+optuna] Score={score:.4f} |A={best.user_attrs.get('A'):.4f} | B={best.user_attrs.get('B'):.4f} | RMSE(IC50)={best.user_attrs.get('RMSE(IC50)') if best.user_attrs.get('RMSE(IC50)') is not None else 'NA'}\")\n",
    "\n",
    "    best_params = dict(\n",
    "        objective='regression',\n",
    "        **best.params,\n",
    "        random_state=CFG['SEED'],\n",
    "        verbose=-1\n",
    "    )\n",
    "\n",
    "    models = train_oof_ensemble(best_params)\n",
    "\n",
    "    test_df = pd.read_csv(\"./test.csv\")\n",
    "    test_df['fingerprint'] = test_df['Smiles'].apply(smiles_to_morgan_fp)\n",
    "    test_df['descriptors'] = test_df['Smiles'].apply(calculate_rdkit_descriptors)\n",
    "\n",
    "    valid_mask = test_df['fingerprint'].apply(lambda x: x is not None) & test_df['descriptors'].apply(lambda x: x is not None)\n",
    "\n",
    "    fp_test = np.stack(test_df.loc[valid_mask, 'fingerprint'].values)\n",
    "    desc_test = np.stack(test_df.loc[valid_mask, 'descriptors'].values)\n",
    "    desc_test = np.nan_to_num(desc_test, nan=desc_mean)\n",
    "    desc_test = scaler.transform(desc_test)\n",
    "    X_test = np.hstack([fp_test.astype(np.float32), desc_test.astype(np.float32)])\n",
    "\n",
    "    X_test_df = pd.DataFrame(X_test, columns=feature_names)\n",
    "\n",
    "    test_preds_p = predict_with_ensemble(models, X_test_df)\n",
    "    test_preds_ic50 = pIC50_to_IC50(test_preds_p)\n",
    "\n",
    "    submission = pd.read_csv(\"./sample_submission.csv\")\n",
    "    pred_df = pd.DataFrame({\n",
    "        'ID': test_df.loc[valid_mask, 'ID'].astype(str).values,\n",
    "        'ASK1_IC50_nM': test_preds_ic50\n",
    "    })\n",
    "\n",
    "    submission['ID'] = submission['ID'].astype(str)\n",
    "    out = submission[['ID']].merge(pred_df, on='ID', how='left')\n",
    "\n",
    "    ic50_mean = df['ic50'].mean()\n",
    "    out['ASK1_IC50_nM'] = pd.to_numeric(out['ASK1_IC50_nM'], errors='coerce').fillna(ic50_mean).clip(lower=1e-6).round(6)\n",
    "\n",
    "    os.makedirs(\"result_jy\", exist_ok=True)\n",
    "    out_path = \"result_jy/lgbm_optuna_submission.csv\"\n",
    "    out.to_csv(out_path, index=False)\n",
    "    print(f\"제출 파일 저장 완료: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
